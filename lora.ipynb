{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks import DemoNet\n",
    "import peft\n",
    "import torch\n",
    "from utils import get_dataset_torch, AverageMeter\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel, im_size, num_classes, class_names, dst_train, dst_test, testloader, trainloader, valoader   = get_dataset_torch('MNIST', 'data', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "epochs = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "ACCURACY = MulticlassAccuracy(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, trainloader, valoader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        data_loop_train = tqdm(enumerate(trainloader), total=len(trainloader), colour='red')\n",
    "        train_accuracy = AverageMeter()\n",
    "        train_loss = AverageMeter()\n",
    "        for _, data in data_loop_train:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            accuracy = ACCURACY(outputs, labels)\n",
    "\n",
    "            train_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "            train_loss.update(loss.item(), inputs.size(0))\n",
    "            data_loop_train.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "            data_loop_train.set_postfix(loss=train_loss.avg, accuracy=train_accuracy.avg)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            data_loop_val = tqdm(enumerate(valoader), total=len(valoader), colour='green')\n",
    "            val_accuracy = AverageMeter()\n",
    "            val_loss = AverageMeter()\n",
    "            for _, data in data_loop_val:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "                outputs = model(inputs)\n",
    "                accuracy = ACCURACY(outputs, labels)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss.update(loss.item(), inputs.size(0))\n",
    "                val_accuracy.update(accuracy.item(), inputs.size(0))\n",
    "                data_loop_val.set_description(f'Epoch {epoch+1}/{epochs}')\n",
    "                data_loop_val.set_postfix(loss=val_loss.avg, accuracy=accuracy.item())\n",
    "\n",
    "    torch.save(model.state_dict(), 'model_without_lora.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train without lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 2, 28, 28]              20\n",
      "            Linear-2                   [-1, 10]           3,930\n",
      "================================================================\n",
      "Total params: 3,950\n",
      "Trainable params: 3,950\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "print(summary(model, (1, 28, 28)))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 88.43it/s, accuracy=0.867, loss=0.454]\n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 107.74it/s, accuracy=0.738, loss=0.264]\n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 85.84it/s, accuracy=0.924, loss=0.228]\n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 105.22it/s, accuracy=0.817, loss=0.213]\n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 85.48it/s, accuracy=0.935, loss=0.196]\n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 103.21it/s, accuracy=0.9, loss=0.195]  \n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 83.51it/s, accuracy=0.941, loss=0.179]\n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 100.71it/s, accuracy=1, loss=0.186]    \n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:18<00:00, 90.19it/s, accuracy=0.942, loss=0.171]\n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 104.01it/s, accuracy=0.812, loss=0.172]\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train with lora**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', networks.DemoNet),\n",
       " ('conv1', torch.nn.modules.conv.Conv2d),\n",
       " ('linear', torch.nn.modules.linear.Linear)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(n, type(m)) for n, m in DemoNet().named_modules()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = peft.LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"conv1\", \"linear\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,304 || all params: 7,254 || trainable%: 45.5473\n"
     ]
    }
   ],
   "source": [
    "model = DemoNet().to(device)\n",
    "model_copy = copy.deepcopy(model)\n",
    "peft_model = peft.get_peft_model(model, config)\n",
    "optimizer = torch.optim.Adam(peft_model.parameters(), lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:19<00:00, 85.57it/s, accuracy=0.807, loss=0.58] \n",
      "Epoch 1/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 111.40it/s, accuracy=1, loss=0.367]    \n",
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 81.79it/s, accuracy=0.89, loss=0.336] \n",
      "Epoch 2/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:02<00:00, 89.94it/s, accuracy=0.889, loss=0.32] \n",
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 81.15it/s, accuracy=0.901, loss=0.312]\n",
      "Epoch 3/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 97.93it/s, accuracy=0.906, loss=0.319] \n",
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:21<00:00, 79.66it/s, accuracy=0.901, loss=0.303]\n",
      "Epoch 4/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 100.56it/s, accuracy=1, loss=0.309]    \n",
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 1688/1688 [00:20<00:00, 84.05it/s, accuracy=0.905, loss=0.296]\n",
      "Epoch 5/5: 100%|\u001b[32m██████████\u001b[0m| 188/188 [00:01<00:00, 94.77it/s, accuracy=1, loss=0.302]    \n"
     ]
    }
   ],
   "source": [
    "train(peft_model, optimizer, criterion, trainloader, valoader, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New parameter model.conv1.lora_A.default.weight |    72 parameters | updated\n",
      "New parameter model.conv1.lora_B.default.weight |    16 parameters | updated\n",
      "New parameter model.linear.lora_A.default.weight |  3136 parameters | updated\n",
      "New parameter model.linear.lora_B.default.weight |    80 parameters | updated\n"
     ]
    }
   ],
   "source": [
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" not in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"New parameter {name:<30} | {param.numel():>5} parameters | updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter model.conv1.base_layer.weight  |    18 parameters | not updated\n",
      "Parameter model.conv1.base_layer.bias    |     2 parameters | not updated\n",
      "Parameter model.linear.base_layer.weight |  3920 parameters | not updated\n",
      "Parameter model.linear.base_layer.bias   |    10 parameters | not updated\n"
     ]
    }
   ],
   "source": [
    "params_before = dict(model_copy.named_parameters())\n",
    "for name, param in peft_model.base_model.named_parameters():\n",
    "    if \"lora\" in name:\n",
    "        continue\n",
    "\n",
    "    print(f\"Parameter {name:<30} | {param.numel():>5} parameters | not updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leon_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
